theta0 <- exp(-c(1:40)/3)
theta1 <- exp(-c(1:40)/2)
theta1[c(1,9:40)] = 0
theta0[c(1,9:40)] = 0
#set mean functions
mu0 <-  rep(0, 8)
mu1 <-  rep(0, 8)
test1 = function(x, return_scores_too){
if(Ys[x]==0){
return(generate_latent_process(theta=theta0, mu_coeff =mu0, tt=seq(0,1, len=D), n=1, return_scores_too))
}
if(Ys[x]==1){
return(generate_latent_process(theta=theta1, mu_coeff =mu1, tt=seq(0,1, len=D), n=1, return_scores_too))
}
}
vec = matrix(1:N, ncol = 1)
if(return_scores_too){
Vall = apply(vec, 1,  function(x) test1(x, return_scores_too))
V0 = t(matrix(unlist(lapply(Vall, function(x) x$X)), nrow = D))
V_scores = matrix(unlist(lapply(Vall, function(x) x$scores)), ncol = N)
}else{
V0 = t(apply(vec, 1,  function(x) test1(x, return_scores_too)))
}
#convert values into matrices at the observed values
beta0_true_mat = kronecker(matrix(1, nrow=IJ), matrix(beta0_true, ncol=D)) #Mean function
for(i in 1:N){
x = V0[i,]
if(i == 1){
V_mat = matrix(rep(x, each = J),nrow=J)
}else{
V_mat = rbind(V_mat, matrix(rep(x, each = J),nrow=J))
}
}
#Second Level eigenfunctions
psi_21 = sqrt(2)*cos(4*pi*grid)
psi_22 = sqrt(2)*sin(4*pi*grid)
psi_2=cbind(psi_21, psi_22)
lambda2=matrix(c(0.25, 0.08), nrow=1)
#select second level eigenfunctions
c_21=rnorm(IJ, 0, lambda2[1])
c_22=rnorm(IJ, 0, lambda2[2])
#second level/daily effects
c_21_mat = kronecker( matrix(c_21, ncol=1), matrix(psi_21, nrow=1))
c_22_mat = kronecker( matrix(c_22, ncol=1), matrix(psi_22, nrow=1))
Curves = beta0_true_mat + V_mat +
c_21_mat + c_22_mat
#if binary curves wanted
if(binary){
#binary_values
Curves_binary <- t(generate_binary_fns(t(Curves)))
}else{
#non_binary
epsilon = matrix(rnorm(N*D*J, 0, sigma), ncol=D)
Curves_binary = Curves+epsilon
}
if(return_scores_too){
return(list(Curves_binary = Curves_binary, V_scores=V_scores))
}
return(Curves_binary)
}
}
#' Functions used to generate latent state data in the various scenarios in accompanying paper
#' @param scenario Which scenario to generate S data
#' @param Curves_binary The binary-valued functional data
#' @param N Total number of subjects to generate data for
#' @param J Number of realizations
#' @param Ys Group assignments for the N individuals
#' @param alpha1 probability for latent state i ngroup 1
#' @param alpha2 probability for latent state in group 2
#' @return Binary or latent curves with latent states
generate_data_with_S = function(scenario = 3, Curves_binary, N, J, Ys, alpha1 = 2/3, alpha2 = 1/4){
#define the S_matrix
S_mat = matrix(NA, nrow = N, ncol = J)
#constant
if(scenario == 1){
alpha1 = 0.4
alpha2 = 0.6
test1 = function(x){
if(x==1){
return(rbinom(J, 1, alpha1))
}
return(rbinom(J, 1, alpha2))
}
S_mat = t(sapply(Ys, test1))
}
if(scenario == 2){
alpha1 = 0.5
alpha2 = 0.25
#Make sure to change the alpha1 scores
test1 = function(x){
if(x==1){
return(c(rbinom(floor(J/2), 1, alpha1), rbinom(J-floor(J/2), 1, alpha2)))
}else{
probs = rep(c(alpha1, alpha2), ceiling(J/2))
return(rbinom(J, 1, probs))
}
}
S_mat = t(sapply(Ys, test1))
}
if(scenario == 3){
#Make sure to change the alpha1 scores
test1 = function(x){
if(x==1){
return(rbinom(J, 1, alpha1))
}else{
Js = 1:J
probs = 2/3-(1/Js)*(1/4)
return(rbinom(J, 1, probs))
}
}
S_mat = t(sapply(Ys, test1))
}
if(scenario == 5){
alpha1 = 0.5
alpha2 = 0.5
test1 = function(x){
if(x==1){
return(rbinom(J, 1, alpha1))
}
return(rbinom(J, 1, alpha2))
}
S_mat = t(sapply(Ys, test1))
}
if(scenario == 4){
alpha1 = c(0.4543210 , 0.4098765 , 0.4370370 , 0.4197531 , 0.3975309 , 0.4345679 , 0.4246914 , 0.4222222,
0.3851852 , 0.3925926 , 0.4543210 , 0.4493827 , 0.4543210 , 0.4469136 , 0.4098765 , 0.3950617,
0.4024691 , 0.4493827 , 0.4617284 , 0.4814815 , 0.4296296 , 0.4518519 , 0.4395062 , 0.4617284,
0.4395062 , 0.4666667 , 0.4567901 , 0.4716049 , 0.4320988 , 0.4592593 , 0.4592593 , 0.4790123,
0.4938272 , 0.5037037 , 0.5037037 , 0.4888889 , 0.4691358 , 0.4617284 , 0.4740741 , 0.5358025,
0.5358025 , 0.5209877 , 0.5135802 , 0.5012346 , 0.5234568 , 0.5185185 , 0.5111111 , 0.5555556,
0.5407407 , 0.5407407)
alpha2 = c(0.26824458 , 0.36982249 , 0.08974359 , 0.36883629 , 0.11143984 , 0.40729783 , 0.09861933 , 0.56213018,
0.37080868 , 0.17751479 , 0.06213018 , 0.13214990 , 0.08678501 , 0.09566075 , 0.19526627 , 0.16370809,
0.26331361 , 0.35305720 , 0.23372781 , 0.26923077 , 0.37771203 , 0.39743590 , 0.18639053 , 0.20216963,
0.14003945 , 0.29881657 , 0.16863905 , 0.18441815 , 0.25345168 , 0.32741617 , 0.21794872 , 0.17357002,
0.06607495 , 0.14990138 , 0.16962525 , 0.27514793 , 0.10946746 , 0.24260355 , 0.20019724 , 0.18244576,
0.26725838 , 0.23076923 , 0.24358974 , 0.19428008 , 0.22879684 , 0.15976331 , 0.32248521 , 0.18836292,
0.24161736 , 0.52761341)
#Make sure to change the alpha1 scores
test1 = function(x){
if(x==1){
return(rbinom(J, 1, alpha1))
}else{
return(rbinom(J, 1, alpha2))
}
}
alpha1 = alpha1[1:J]
alpha2 = alpha2[1:J]
S_mat = t(sapply(Ys, test1))
}
if(scenario == 6){
beta1 = c(-1.13, 1.15, 0.81, 0.64)
beta2 = c(-1.22, 0.63, 0.66, 0.04)
pi1 = c(0.20, 0.08, 0.07, 0.09, 0.08, 0.08, 0.09, 0.31)
pi2 = c(0.41, 0.11, 0.11, 0.06, 0.11, 0.06, 0.06, 0.08)
initial_combos = as.matrix.data.frame(expand.grid(rep(list(0:1),3)))
#Make sure to change the alpha1 scores
test1 = function(x){
if(x==1){
S_s = rep(NA, J)
initals = c(initial_combos[sample(1:8, 1, prob = pi1, replace = T),])
S_s[1:3] = initals
for(j in 4:J){
S_pre =  S_s[(j-3):(j-1)]
alpha.cur = invlogit(beta1[1] + sum(beta1[2:4]*S_pre))
S_s[j] = rbinom(1, 1, alpha.cur)
}
return(c(S_s))
}else{
S_s = rep(NA, J)
initals = c(initial_combos[sample(1:8, 1, prob = pi2, replace = T),])
S_s[1:3] = initals
for(j in 4:J){
S_pre =  S_s[(j-3):(j-1)]
alpha.cur = invlogit(beta2[1] + sum(beta2[2:4]*S_pre))
S_s[j] = rbinom(1, 1, alpha.cur)
}
return(c(S_s))
}
}
S_mat = t(sapply(Ys, test1))
}
if(scenario == 7){
beta1 = c(-1.13, 1.15, 0.81, 0.64)
beta2 = c(-1.22, 0.63, 0, 0)
pi1 = c(0.20, 0.08, 0.07, 0.09, 0.08, 0.08, 0.09, 0.31)
pi2 = c(0.41, 0.11, 0.11, 0.06, 0.11, 0.06, 0.06, 0.08)
initial_combos = as.matrix.data.frame(expand.grid(rep(list(0:1),3)))
#Make sure to change the alpha1 scores
test1 = function(x){
if(x==1){
S_s = rep(NA, J)
initals = c(initial_combos[sample(1:8, 1, prob = pi1, replace = T),])
S_s[1:3] = initals
for(j in 4:J){
S_pre =  S_s[(j-3):(j-1)]
alpha.cur = invlogit(beta1[1] + sum(beta1[2:4]*S_pre))
S_s[j] = rbinom(1, 1, alpha.cur)
}
return(c(S_s))
}else{
S_s = rep(NA, J)
initals = c(initial_combos[sample(1:8, 1, prob = pi2, replace = T),])
S_s[1:3] = initals
for(j in 4:J){
S_pre =  S_s[(j-3):(j-1)]
alpha.cur = invlogit(beta2[1] + sum(beta2[2:4]*S_pre))
S_s[j] = rbinom(1, 1, alpha.cur)
}
return(c(S_s))
}
}
S_mat = t(sapply(Ys, test1))
}
return_ls = list()
return_ls$s_mat = S_mat
S_mat_s = c(t(S_mat))
D = dim(Curves_binary)[2]
test1 = function(x){
if(S_mat_s[x]==0){
return(rep(0, D))
}
return(Curves_binary[x,])
}
NJ = dim(Curves_binary)[1]
return_ls$Curves_binary = t(sapply(1:NJ, test1))
return(return_ls)
}
#' Function that makes a matrix positive semi definite
#' @param x matrix to make semi-postive definite
#' @return  semi-postive definite of x
make_pos_semi_def = function(x){
x2 = svd(x)
#remove negative vals
x2$d=ifelse(x2$d>0, x2$d, 0)
#remake matrix
x2=x2$u%*%diag(x2$d)%*%t(x2$v)
return(x2)
}
#' Function: Get number of functions based on the pvs and eigenvalues
#' @param pve Value [0,1] to determine number of eigenfunctions
#' @param vec vector of eigenvalues
#' @param set_max_number If you want a maximum number of values
#' @return The number of eigenfunctions and eigenvalues for KL-approximation
get_length_pve = function(pve, vec, set_max_number = NA){
#total sum of eigenvals
s=sum(vec)
vec2 = cumsum(vec)
vec=vec2/s
#return(which(vec>=pve)[1])
if(!is.na(set_max_number)){
if(which(vec>=pve)[1] < set_max_number){
return(which(vec>=pve)[1])
}else{
return(set_max_number)
}
}
return(which(vec>=pve)[1])
}
#' Function to estimate eiginfunctions
#' @param K_b estimate of a covariance matrix
#' @param pve Proportion of variance explained
#' @param fix_num_of_functions set the number of eigenfunctions to be returned
#' @return The eigenvalues and eigenvectors from
estimate_eigenfunctions = function(K_b, pve=0.98, fix_num_of_functions=NA){
#SVD on matrix
svd_kb = svd(K_b)
#Only get the pve length if the number of functions is not given
if(is.na(fix_num_of_functions)){
#get number of components
pb = get_length_pve(pve, svd_kb$d)
}else{
pb = fix_num_of_functions
}
eigen_vals1 = svd_kb$d[1:pb]
eigen_funcs1 = svd_kb$v[,1:pb]
return(list(eigen_vals1=eigen_vals1, eigen_funcs1=eigen_funcs1))
}
#' Function used to generate the latent curves for simulation scenarios where I define various scenarios, inspired by Delaigle and Hall(2012)
#' @param theta  Define latent process X_i using Fourier basis
#' @param mu_coeff vector of mean coefficients
#' @param tt grid of points which the functions are observed
#' @param n number of individuals to generate data for
#' @param return_scores_too Indicator to determine whether or not to return the coefficients too
#' @return latent process observed on points defined by grid
generate_latent_process <- function(theta, mu_coeff, tt, n=20, return_scores_too = F){
# tt<- seq(0,1, len=101)
K <- length(theta); Khalf <- round(K/2)
Kseqeven <- 2*(1:Khalf); Kseqodd<- Kseqeven-1
Phitt1 <- sapply(c(1:Khalf), function(j) sqrt(2) * sin(2*pi*j*tt))
Phitt2 <- sapply(c(1:Khalf), function(j) sqrt(2) * cos(2*pi*j*tt))
Phitt <- matrix(0, ncol=2*Khalf, nrow=length(tt))
Phitt[,Kseqeven] <- Phitt1
Phitt[,Kseqodd] <- Phitt2
Phitt <-cbind(rep(1, length(tt)), Phitt)[, 1:K]
Z <- matrix(rnorm (K*n), ncol=n)
Lambda_half <- diag(sqrt(theta))
mu <- rep(0, K)
mu[1:length(mu_coeff)] <- mu_coeff
X <- Phitt %*% (Lambda_half%*% Z + mu)
if(return_scores_too){
return(list(X = X, scores = (Lambda_half%*% Z+mu)[theta!=0]))
}else{
return(X)
}
X
}
#' Function used to generate the binary valued functional data from latent curves
#' @param X is the latent functional data
#' @return Binary valued functional data determined by X
generate_binary_fns <- function(X){
length_tt <- nrow(X)
probs<-  1/(1+exp(-X))
out <- matrix(rbinom(length(X), 1,  c(probs)), nrow=length_tt)
out
}
#' Function to return the logit of x
#' @param x value to input
#' @return Returns the logit of x
logit <- function(x){
return(log(x/(1-x)))
}
#' Function to return the inverse of the logit
#' @param x value to input
#' @return Returns the invlogit of x
invlogit <- function(x){
return(1/(1+exp(-x)))
}
#' function to return the derivative of the logit
#' @param x value to input
#' @return Returns the derivative of the logit of x
d_logit <- function(x){
return( invlogit(x)*(1-invlogit(x)))
}
#' Function: To get the density values of new scores for an individual in a given class
#' @param densities List of densities of scores within each group
#' @param scores matrix of scores for the N individuals
#' @param classes matrix of classes (these are not the true classes but the value to be evaluated)
#' @param i which individual to evaluate
#' @return Density values of the new scores for individual i
get_pdf_den2 = function(densities, scores, classes, i){
#get score for current user
score_cur = scores[i,]
#get class for current user
class_cur = classes[i]
#get density for current class
dens_cur = densities[[class_cur]]
pdf.vals = rep(NA, length(dens_cur))
#for each component
for(k in 1:length(dens_cur)){
#get K comp density
dens_cur_k = dens_cur[[k]]
#approximate the function
approx_fun_den = approxfun(dens_cur_k)
#get new score
xnew = score_cur[k]
#get value in the density
#pdf.vals[k]  = approx_fun_den(xnew)
#changed to probability approx
delta0 = diff(dens_cur_k$x)[1]
lower0 = xnew
upper0 = xnew+delta0
#if new value is outside of defined range
if(lower0<=min(dens_cur_k$x)){
xnew=min(dens_cur_k$x)
lower0 = xnew
upper0 = xnew+delta0
}
#if new vlaue is outside of defined range
if(upper0>=max(dens_cur_k$x)){
xnew=max(dens_cur_k$x)
lower0 = xnew - delta0
upper0 = xnew
}
pdf.vals[k]  = c(c(integrate(approx_fun_den, lower = lower0, upper = upper0))$value)
}
return(pdf.vals)
}
#' Function: Estimate predicted values for a given value of scaling parameter h
#' @param scores N x K matrix of scores in the training set
#' @param classes Group labels vector of length N
#' @param prior_g vector of prior probability of being in each group, sums up to 1
#' @param scores_test N_test x K matrix of scores in the testing set
#' @param h multiplier for kernel based density function
#' @param s_mat_hat_train matrix of estimated S latent state values training set
#' @param s_mat_hat_test matrix of estimated S latent state values testing set
#' @param P_max Lag in the gAR models
#' @param static_train Covariates for the classifier in the training set accounts
#' @param static_test Covariates for the classifier in the testing set accounts
#' @param alpha_js Estimated probability oflatent states across the realizations
#' @return Predicted groups for the indivdiuals
nb_updated = function(scores, classes, prior_g, scores_test,
s_mat_hat_train, s_mat_hat_test, alpha_js=NA,  h = 1.06, P_max = 3,
static_train = NA, static_test = NA){
#in case scores are N x 1 matrix that is read as a vector
if(length(scores)==length(classes)){
scores = matrix(scores, ncol = 1)
scores_test = matrix(scores_test, ncol = 1)
}
#get K
nd = dim(scores)[2]
#get number of groups
ng = length(unique(classes))
#initialize list
densities = list()
#estimate density at each K for each group
for(i in 1:ng){
densities[[i]]=list()
for(k in 1:nd){
densities[[i]][[k]] = density(scores[classes==i,k],
kernel = "gaussian",
bw = h*sd(scores[classes==i,k]))
}
}
# get number of test functions
n_test = dim(scores_test)[1]
p.mat = matrix(NA, nrow = n_test, ncol = length(prior_g))
vec = matrix(1:n_test, ncol = 1)
#get_ps = rep(NA, ng)
#P_max = min(P_max, floor(J/5))
#tol = 0.001
#for(l in 1:ng){
#  aics.cur = sapply(0:P_max, function(x) fit_ajs_model(l, x, s_mat_hat_train, aic = T, classes, static_train))
#  get_ps[l] = (0:P_max)[which.min(aics.cur)]
#  #diff(aics.cur)/aics.cur[2:P_max]
#}
#set ps to 3
get_ps = rep(P_max, ng)
models_ls = list()
p.mat_s = matrix(NA, nrow = n_test, ncol = length(unique(classes)))
for(l in 1:ng){
models_ls[[l]] = fit_ajs_model(l, get_ps[l], s_mat_hat_train, classes = classes, static_train = static_train)
p.mat_s[,l]  = sapply(1:n_test, function(x) predict_new_ind_group_model(x, l, get_ps[l],  models_ls, s_mat_hat_test, static_test))
}
#For each group get the Bayes classifier value of probability of being in that group
for(i in 1:ng){
#apply for each user get the probability for each component in that group
pdf.vals.test.1 = t(apply(vec, 1,
function(x)  get_pdf_den2(densities, scores_test, rep(i, n_test), x)))
#apply for each user to get the product of those K probabilities
pdf_vals = apply(pdf.vals.test.1, 1, prod)
pdf.vals.test.1 = cbind.data.frame(pdf_vals, p.mat_s[,i])
pdf_vals = apply(pdf.vals.test.1, 1, prod)
#pdf_vals = apply(pdf.vals.test.1, 1, mean)
#pdf_vals = apply(pdf.vals.test.1, 1, function(x) sum(x*c(gamma0, 1-gamma0)))
#multiply by prior probability
p.mat[,i] = prior_g[i] * pdf_vals #p.mat is now matrix of Bayes probabilities
}
#get guess based on which is the max
guess = apply(p.mat, 1, which.max)
return(guess)
}
#' Function: Grid search to estimate predicted values and estimate the values of h
#' @param scores N x K matrix of 1st level scores in the training set
#' @param classes Group labels vector of length N
#' @param prior_g vector of prior probability of being in each group, sums up to 1
#' @param scores_test N_test x K matrix of scores in the testing set
#' @param min.h min possible value for the multiplier
#' @param max.h maximum possible value for the multiplier
#' @param n_grid number of values between min.h and max.h to search over
#' @param CV Number of folds for cross validation
roxygen2::roxygenise()
devtools::document()
devtools::check()
devtools::release_checks()
devtools::release()
devtools::spell_check()
devtools::spell_check()
devtools::spell_check()
library(gFPCAClassif)
devtools::spell_check()
devtools::release_checks()
devtools::release_checks()
devtools::spell_check()
searn
search()
search()
devtools::document()
devtools::document()
warnings()
devtools::document()
devtools::document()
devtools::document()
warnings()
devtools::document()
devtools::document()
warnings()
library(gFPCAClassif)
devtools::document()
devtools::spell_check()
devtools::document()
devtools::spell_check()
devtools::document()
devtools::spell_check()
devtools::document()
devtools::spell_check()
devtools::document()
devtools::document()
devtools::spell_check()
1+1
library(gFPCAClassif)
devtools::document()
devtools::document()
devtools::document()
library(gFPCAClassif)
library(gFPCAClassif)
devtools::release_checks())
devtools::release_checks()
devtools::release()
devtools::check_rhub()
devtools::release()
devtools::check_win_devel()
